# check_dataset_size.py
from pathlib import Path
import pandas as pd

# === ã‚ãªãŸã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆã«åˆã‚ã›ã‚‹ ===
in_dir = Path("./data/input")

# === ã™ã¹ã¦ã® *_cpg_input.pkl ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ç´¢ ===
files = sorted(in_dir.glob("*_cpg_input.pkl"))
if not files:
    raise FileNotFoundError("âš ï¸ data/input/ ã« *_cpg_input.pkl ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

total = 0
print("=== ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ãƒã‚§ãƒƒã‚¯ ===")
for f in files:
    df = pd.read_pickle(f)
    n = len(df)
    total += n
    print(f"{f.name:25s}: {n:6d} samples")

print(f"\nğŸ“Š åˆè¨ˆ: {total:,} samples\n")

# ã‚ªãƒ—ã‚·ãƒ§ãƒ³: å„ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ—åã¨Dataå‹ã‚‚ç¢ºèªã—ãŸã„å ´åˆ
sample_file = files[0]
df_sample = pd.read_pickle(sample_file)
print("ä¾‹:", sample_file.name)
print("åˆ—:", list(df_sample.columns))
print("å…ˆé ­è¡Œ:")
print(df_sample.head(1))
